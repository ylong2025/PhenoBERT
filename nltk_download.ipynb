{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If donwload failed, you can download the data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "print(\"Checking and downloading required NLTK data...\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    print(\"✓ Punkt tokenizer already installed\")\n",
    "except LookupError:\n",
    "    print(\"Downloading Punkt tokenizer...\")\n",
    "    try:\n",
    "        nltk.download('punkt', download_dir=nltk.data.path[0])\n",
    "        print(\"✓ Punkt tokenizer installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading Punkt tokenizer: {e}\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    print(\"✓ Stopwords already installed\")\n",
    "except LookupError:\n",
    "    print(\"Downloading stopwords...\")\n",
    "    try:\n",
    "        nltk.download('stopwords', download_dir=nltk.data.path[0])\n",
    "        print(\"✓ Stopwords installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading stopwords: {e}\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "    print(\"✓ WordNet already installed\")\n",
    "except LookupError:\n",
    "    print(\"Downloading WordNet...\")\n",
    "    try:\n",
    "        nltk.download('wordnet', download_dir=nltk.data.path[0])\n",
    "        print(\"✓ WordNet installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading WordNet: {e}\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "    print(\"✓ Punkt tab tokenizer already installed\")\n",
    "except LookupError:\n",
    "    print(\"Downloading Punkt tab tokenizer...\")\n",
    "    try:\n",
    "        nltk.download('punkt_tab', download_dir=nltk.data.path[0])\n",
    "        print(\"✓ Punkt tab tokenizer installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading Punkt tab tokenizer: {e}\")\n",
    "\n",
    "print(\"All required NLTK data is ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已解压 /root/nltk_data/grammars/spanish_grammars.zip\n",
      "已解压 /root/nltk_data/grammars/basque_grammars.zip\n",
      "已解压 /root/nltk_data/grammars/large_grammars.zip\n",
      "已解压 /root/nltk_data/grammars/book_grammars.zip\n",
      "已解压 /root/nltk_data/grammars/sample_grammars.zip\n",
      "已解压 /root/nltk_data/corpora/verbnet3.zip\n",
      "已解压 /root/nltk_data/corpora/sinica_treebank.zip\n",
      "已解压 /root/nltk_data/corpora/names.zip\n",
      "已解压 /root/nltk_data/corpora/switchboard.zip\n",
      "已解压 /root/nltk_data/corpora/ycoe.zip\n",
      "已解压 /root/nltk_data/corpora/paradigms.zip\n",
      "已解压 /root/nltk_data/corpora/wordnet2021.zip\n",
      "已解压 /root/nltk_data/corpora/cess_cat.zip\n",
      "已解压 /root/nltk_data/corpora/nombank.1.0.zip\n",
      "已解压 /root/nltk_data/corpora/city_database.zip\n",
      "已解压 /root/nltk_data/corpora/state_union.zip\n",
      "已解压 /root/nltk_data/corpora/comtrans.zip\n",
      "已解压 /root/nltk_data/corpora/english_wordnet.zip\n",
      "已解压 /root/nltk_data/corpora/dolch.zip\n",
      "已解压 /root/nltk_data/corpora/timit.zip\n",
      "已解压 /root/nltk_data/corpora/framenet_v15.zip\n",
      "已解压 /root/nltk_data/corpora/twitter_samples.zip\n",
      "已解压 /root/nltk_data/corpora/machado.zip\n",
      "已解压 /root/nltk_data/corpora/lin_thesaurus.zip\n",
      "已解压 /root/nltk_data/corpora/dependency_treebank.zip\n",
      "已解压 /root/nltk_data/corpora/shakespeare.zip\n",
      "已解压 /root/nltk_data/corpora/mac_morpho.zip\n",
      "已解压 /root/nltk_data/corpora/jeita.zip\n",
      "已解压 /root/nltk_data/corpora/universal_treebanks_v20.zip\n",
      "已解压 /root/nltk_data/corpora/indian.zip\n",
      "已解压 /root/nltk_data/corpora/propbank.zip\n",
      "已解压 /root/nltk_data/corpora/bcp47.zip\n",
      "已解压 /root/nltk_data/corpora/masc_tagged.zip\n",
      "已解压 /root/nltk_data/corpora/omw.zip\n",
      "已解压 /root/nltk_data/corpora/conll2002.zip\n",
      "已解压 /root/nltk_data/corpora/swadesh.zip\n",
      "已解压 /root/nltk_data/corpora/gutenberg.zip\n",
      "已解压 /root/nltk_data/corpora/reuters.zip\n",
      "已解压 /root/nltk_data/corpora/movie_reviews.zip\n",
      "已解压 /root/nltk_data/corpora/abc.zip\n",
      "已解压 /root/nltk_data/corpora/comparative_sentences.zip\n",
      "已解压 /root/nltk_data/corpora/product_reviews_1.zip\n",
      "已解压 /root/nltk_data/corpora/wordnet_ic.zip\n",
      "已解压 /root/nltk_data/corpora/omw-1.4.zip\n",
      "已解压 /root/nltk_data/corpora/gazetteers.zip\n",
      "已解压 /root/nltk_data/corpora/knbc.zip\n",
      "已解压 /root/nltk_data/corpora/alpino.zip\n",
      "已解压 /root/nltk_data/corpora/cess_esp.zip\n",
      "已解压 /root/nltk_data/corpora/panlex_swadesh.zip\n",
      "已解压 /root/nltk_data/corpora/udhr.zip\n",
      "已解压 /root/nltk_data/corpora/pil.zip\n",
      "已解压 /root/nltk_data/corpora/problem_reports.zip\n",
      "已解压 /root/nltk_data/corpora/words.zip\n",
      "已解压 /root/nltk_data/corpora/brown.zip\n",
      "已解压 /root/nltk_data/corpora/conll2000.zip\n",
      "已解压 /root/nltk_data/corpora/kimmo.zip\n",
      "已解压 /root/nltk_data/corpora/wordnet.zip\n",
      "已解压 /root/nltk_data/corpora/sentiwordnet.zip\n",
      "已解压 /root/nltk_data/corpora/smultron.zip\n",
      "已解压 /root/nltk_data/corpora/subjectivity.zip\n",
      "已解压 /root/nltk_data/corpora/treebank.zip\n",
      "已解压 /root/nltk_data/corpora/pl196x.zip\n",
      "已解压 /root/nltk_data/corpora/inaugural.zip\n",
      "已解压 /root/nltk_data/corpora/sentence_polarity.zip\n",
      "已解压 /root/nltk_data/corpora/qc.zip\n",
      "已解压 /root/nltk_data/corpora/framenet_v17.zip\n",
      "已解压 /root/nltk_data/corpora/semcor.zip\n",
      "已解压 /root/nltk_data/corpora/crubadan.zip\n",
      "已解压 /root/nltk_data/corpora/brown_tei.zip\n",
      "已解压 /root/nltk_data/corpora/senseval.zip\n",
      "已解压 /root/nltk_data/corpora/genesis.zip\n",
      "已解压 /root/nltk_data/corpora/stopwords.zip\n",
      "已解压 /root/nltk_data/corpora/nonbreaking_prefixes.zip\n",
      "已解压 /root/nltk_data/corpora/wordnet2022.zip\n",
      "已解压 /root/nltk_data/corpora/conll2007.zip\n",
      "已解压 /root/nltk_data/corpora/europarl_raw.zip\n",
      "已解压 /root/nltk_data/corpora/webtext.zip\n",
      "已解压 /root/nltk_data/corpora/mte_teip5.zip\n",
      "已解压 /root/nltk_data/corpora/ptb.zip\n",
      "已解压 /root/nltk_data/corpora/ieer.zip\n",
      "已解压 /root/nltk_data/corpora/pros_cons.zip\n",
      "已解压 /root/nltk_data/corpora/ppattach.zip\n",
      "已解压 /root/nltk_data/corpora/nps_chat.zip\n",
      "已解压 /root/nltk_data/corpora/wordnet31.zip\n",
      "已解压 /root/nltk_data/corpora/biocreative_ppi.zip\n",
      "已解压 /root/nltk_data/corpora/rte.zip\n",
      "已解压 /root/nltk_data/corpora/floresta.zip\n",
      "已解压 /root/nltk_data/corpora/verbnet.zip\n",
      "已解压 /root/nltk_data/corpora/extended_omw.zip\n",
      "已解压 /root/nltk_data/corpora/unicode_samples.zip\n",
      "已解压 /root/nltk_data/corpora/udhr2.zip\n",
      "已解压 /root/nltk_data/corpora/opinion_lexicon.zip\n",
      "已解压 /root/nltk_data/corpora/toolbox.zip\n",
      "已解压 /root/nltk_data/corpora/chat80.zip\n",
      "已解压 /root/nltk_data/corpora/pe08.zip\n",
      "已解压 /root/nltk_data/corpora/cmudict.zip\n",
      "已解压 /root/nltk_data/corpora/product_reviews_2.zip\n",
      "已解压 /root/nltk_data/models/wmt15_eval.zip\n",
      "已解压 /root/nltk_data/models/moses_sample.zip\n",
      "已解压 /root/nltk_data/models/word2vec_sample.zip\n",
      "已解压 /root/nltk_data/models/bllip_wsj_no_aux.zip\n",
      "已解压 /root/nltk_data/stemmers/snowball_data.zip\n",
      "已解压 /root/nltk_data/stemmers/rslp.zip\n",
      "已解压 /root/nltk_data/stemmers/porter_test.zip\n",
      "已解压 /root/nltk_data/help/tagsets.zip\n",
      "已解压 /root/nltk_data/help/tagsets_json.zip\n",
      "已解压 /root/nltk_data/misc/perluniprops.zip\n",
      "已解压 /root/nltk_data/misc/mwa_ppdb.zip\n",
      "已解压 /root/nltk_data/sentiment/vader_lexicon.zip\n",
      "已解压 /root/nltk_data/tokenizers/punkt_tab.zip\n",
      "已解压 /root/nltk_data/tokenizers/punkt.zip\n",
      "已解压 /root/nltk_data/chunkers/maxent_ne_chunker_tab.zip\n",
      "已解压 /root/nltk_data/chunkers/maxent_ne_chunker.zip\n",
      "已解压 /root/nltk_data/taggers/averaged_perceptron_tagger_eng.zip\n",
      "已解压 /root/nltk_data/taggers/averaged_perceptron_tagger_ru.zip\n",
      "已解压 /root/nltk_data/taggers/averaged_perceptron_tagger.zip\n",
      "已解压 /root/nltk_data/taggers/maxent_treebank_pos_tagger.zip\n",
      "已解压 /root/nltk_data/taggers/averaged_perceptron_tagger_rus.zip\n",
      "已解压 /root/nltk_data/taggers/universal_tagset.zip\n",
      "已解压 /root/nltk_data/taggers/maxent_treebank_pos_tagger_tab.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# 定义要处理的根目录\n",
    "root_dir = os.path.expanduser('/root/nltk_data')\n",
    "\n",
    "# 递归遍历目录及其子目录\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.zip'):\n",
    "            zip_file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # 打开压缩包\n",
    "                with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                    # 解压到当前目录\n",
    "                    zip_ref.extractall(root)\n",
    "                print(f\"已解压 {zip_file_path}\")\n",
    "            except zipfile.BadZipFile:\n",
    "                print(f\"无法解压 {zip_file_path}，可能是损坏的压缩包。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenobert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
